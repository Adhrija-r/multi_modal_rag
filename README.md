ğŸ“˜ Multi-Modal Retrieval-Augmented Generation (RAG) System

This project implements a complete multi-modal Retrieval-Augmented Generation (RAG) pipeline, designed as part of an AI/ML internship assessment.
It demonstrates the ability to process documents, generate embeddings, store vectors, retrieve relevant information, and produce responses using LLMs â€” all following modular, scalable design principles.

ğŸš€ Project Overview

The Multi-Modal RAG system enables:

Document ingestion (PDFs and text)

Text extraction & cleaning

Chunking using configurable strategies

Embedding generation

Vector database storage

Similarity search for retrieval

LLM-powered answer generation

(Optional) Streamlit-based UI

The architecture follows industry-standard patterns and is fully extensible for future development.

ğŸ§© Features
ğŸ“¥ 1. Document Ingestion
Extracts text from PDFs and pre-processes it for downstream modules.

âœ‚ï¸ 2. Intelligent Chunking
Splits text using customizable logic for optimal embedding performance.

ğŸ§  3. Embeddings
Generates numerical vector representations for each chunk.

ğŸ“š 4. Vector Store
Uses FAISS (or other stores) for efficient similarity search.

ğŸ” 5. Retriever
Fetches the most relevant chunks for a user query.

ğŸ“ 6. RAG Response Generator
Combines:
Retrieved context
User query
to generate high-quality answers.

ğŸ¨ 7. Streamlit UI (Local)
A simple interface to upload documents and ask questions.

ğŸ“ Project Structure
multi_modal_rag/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/          # PDF/Text extraction modules
â”‚   â”œâ”€â”€ chunking/           # Splitting logic
â”‚   â”œâ”€â”€ embeddings/         # Embedding generator
â”‚   â”œâ”€â”€ retriever/          # Vector search
â”‚   â”œâ”€â”€ generation/         # LLM response generation
â”‚   â””â”€â”€ ui/                 # (Optional) Streamlit UI
â”‚
â”œâ”€â”€ docs/                   # Technical report, notes
â”œâ”€â”€ demos/                  # Demo video or screenshots
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation

âš™ï¸ Installation
1ï¸âƒ£ Clone the repository
git clone https://github.com/Adhrija-r/multi_modal_rag.git
cd multi_modal_rag

2ï¸âƒ£ Create a virtual environment
python -m venv venv
source venv/bin/activate      # macOS/Linux
venv\Scripts\activate         # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

â–¶ï¸ Running the RAG Pipeline
Run the backend modules

Each component can be executed independently for testing:

python src/ingestion/pdf_parser.py
python src/chunking/chunker.py
python src/embeddings/embedder.py
python src/retriever/search.py
python src/generation/generator.py

Running the Streamlit Interface (optional)
streamlit run src/ui/app.py

ğŸ§ª How the System Works
1. Ingestion
Extract text from PDF â†’ returns raw text.

2. Chunking
Breaks long text into overlapping windows.

3. Embeddings
Each chunk â†’ vector via embedding model.

4. Vector Store
FAISS index stores all chunk embeddings.

5. Retrieval
For each query:
Convert query â†’ embedding
Retrieve top-k similar chunks

6. Generation
Send context + user query to the LLM.
